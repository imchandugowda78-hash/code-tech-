import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
def load_image(image_path, max_dim=512):
    img = Image.open(image_path)
    long = max(img.size)
    scale = max_dim / long
    img = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)))
    img = np.array(img)
    img = tf.expand_dims(img, axis=0)
    return img
def show_image(image, title=None):
    image = tf.squeeze(image, axis=0)
    image = tf.clip_by_value(image, 0, 255)
    image = image.numpy().astype(np.uint8)
    plt.imshow(image)
    if title:
        plt.title(title)
    plt.axis('off')
    plt.show()
content_image = load_image("content.jpg")
style_image = load_image("style.jpg")
vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')
vgg.trainable = False
style_layers = [
    'block1_conv1',
    'block2_conv1',
    'block3_conv1',
    'block4_conv1',
    'block5_conv1'
]
content_layers = ['block5_conv2']
def get_model():
    outputs = [vgg.get_layer(name).output for name in style_layers + content_layers]
    return tf.keras.Model(vgg.input, outputs)

def gram_matrix(tensor):
    result = tf.linalg.einsum('bijc,bijd->bcd', tensor, tensor)
    return result / tf.cast(tf.shape(tensor)[1] * tf.shape(tensor)[2], tf.float32)
model = get_model()
style_outputs = model(style_image)
content_outputs = model(content_image)

style_features = [gram_matrix(output) for output in style_outputs[:len(style_layers)]]
content_features = content_outputs[len(style_layers):]
generated_image = tf.Variable(content_image, dtype=tf.float32)
optimizer = tf.optimizers.Adam(learning_rate=0.02)
@tf.function()
def train_step(image):
    with tf.GradientTape() as tape:
        outputs = model(image)
        style_output = outputs[:len(style_layers)]
        content_output = outputs[len(style_layers):]

        style_loss = tf.add_n([
            tf.reduce_mean((gram_matrix(style_output[i]) - style_features[i])**2)
            for i in range(len(style_layers))
        ])

        content_loss = tf.reduce_mean((content_output[0] - content_features[0])**2)
        total_loss = style_loss * 1e-2 + content_loss

    grad = tape.gradient(total_loss, image)
    optimizer.apply_gradients([(grad, image)])
    image.assign(tf.clip_by_value(image, 0, 255))
epochs = 5
steps_per_epoch = 100

for epoch in range(epochs):
    for step in range(steps_per_epoch):
        train_step(generated_image)
    print(f"Epoch {epoch+1} completed")
show_image(generated_image, "Styled Image")
